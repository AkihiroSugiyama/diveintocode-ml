{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S22_RNNs.ipynb","provenance":[],"authorship_tag":"ABX9TyPy8ydtqIBV+HsMhU7YBI7M"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mymJO7YU4CCy"},"source":["# Sprint 深層学習スクラッチ リカレントニューラルネットワーク\n","リカレントニューラルネットワーク（RNN） のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n","\n","フォワードプロパゲーションの実装を必須課題とし、バックプロパゲーションの実装はアドバンス課題とします。\n","\n","クラスの名前はScratchSimpleRNNClassifierとしてください。クラスの構造などは以前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。"]},{"cell_type":"markdown","metadata":{"id":"_h8J0hsY4BcG"},"source":["## 【問題1】SimpleRNNのフォワードプロパゲーション実装\n","SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n","\n","\n","フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。\n","\n","\n","バッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。\n","\n","$$a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + B\\\\$$\n","$$h_t = tanh(a_t)$$\n","\n","$a_t$ : 時刻tの活性化関数を通す前の状態 (batch_size, n_nodes)\n","\n","\n","$h_t$ : 時刻tの状態・出力 (batch_size, n_nodes)\n","\n","\n","$x_t$ : 時刻tの入力 (batch_size, n_features)\n","\n","\n","$W_x$ : 入力に対する重み (n_features, n_nodes)\n","\n","\n","$h_{t−1}$ : 時刻t-1の状態（前の時刻から伝わる順伝播） (batch_size, n_nodes)\n","\n","\n","$W_h$ : 状態に対する重み。 (n_nodes, n_nodes)\n","\n","\n","$B$ : バイアス項 (n_nodes,)\n","\n","\n","\n","初期状態 \n","$h_0$ は全て0とすることが多いですが、任意の値を与えることも可能です。\n","\n","\n","上記の処理を系列数n_sequences回繰り返すことになります。RNN全体への入力 $x$ は(batch_size, n_sequences, n_features)のような配列で渡されることになり、そこから各時刻の配列を取り出していきます。\n","\n","\n","分類問題であれば、それぞれの時刻のhに対して全結合層とソフトマックス関数（またはシグモイド関数）を使用します。タスクによっては最後の時刻のhだけを使用することもあります。"]},{"cell_type":"code","metadata":{"id":"h6463REV4-Ks"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUle5rJ14Axe"},"source":["class SimpleRNN:\n","    def __init__(self, activation, optimizer=None, weights=None, intercept=None):\n","        self.activ = activation\n","        self.optimizer = optimizer\n","        \n","        self.w = weights\n","        self.b = intercept\n","\n","    \n","    def forward(self, X, h):    \n","        W_x = self.w[0]\n","        W_h = self.w[1]\n","        \n","        A = X@W_x + h@W_h + self.b\n","        H = self.activ.forward(A)\n","\n","        self.X = X[None,:]\n","        self.h = h\n","        self.output = H\n","        self.A_ = A\n","\n","        return H\n","    \n","\n","class Tanh:\n","    def __init__(self):\n","        self.Z_ = None\n","        self.dA_ = None\n","        \n","    def forward(self, A):\n","        self.Z_ = np.tanh(A)\n","        \n","        return self.Z_\n","    \n","    def backward(self, dZ):\n","        self.dA_ = dZ * (1 - self.Z_**2)\n","        \n","        return self.dA_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6UInPlJS1PlC"},"source":["## 【問題2】小さな配列でのフォワードプロパゲーションの実験\n","小さな配列でフォワードプロパゲーションを考えてみます。\n","\n","\n","入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n","\n","\n","ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。"]},{"cell_type":"code","metadata":{"id":"8ujfDpYD42DQ"},"source":["x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n","w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n","w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n","batch_size = x.shape[0] # 1\n","n_sequences = x.shape[1] # 3\n","n_features = x.shape[2] # 2\n","n_nodes = w_x.shape[1] # 4\n","h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n","b = np.array([1, 1, 1, 1]) # (n_nodes,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYaiEU177VCJ","executionInfo":{"status":"ok","timestamp":1602038366011,"user_tz":-540,"elapsed":672,"user":{"displayName":"杉山明大","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLDWHHPNft0OzQcPMwj3-wE8ShJvR2UKW5D9pFfA=s64","userId":"08086586751154899568"}},"outputId":"33fe5e1e-75e1-4704-8b87-22bb9cc941c9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 手計算\n","H1 = np.tanh(x[0,0]@w_x + h@w_h + b)\n","H2 = np.tanh(x[0,1]@w_x + H1@w_h + b)\n","H3 = np.tanh(x[0,2]@w_x + H2@w_h + b)\n","H3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"hGcZns427Xxl","executionInfo":{"status":"ok","timestamp":1602038376652,"user_tz":-540,"elapsed":691,"user":{"displayName":"杉山明大","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLDWHHPNft0OzQcPMwj3-wE8ShJvR2UKW5D9pFfA=s64","userId":"08086586751154899568"}},"outputId":"272baf25-e173-4239-c6bd-02feeaf4559b","colab":{"base_uri":"https://localhost:8080/"}},"source":["W = (w_x, w_h)\n","B = b\n","rnn = SimpleRNN(Tanh(), weights=W, intercept=B)\n","\n","for s in range(n_sequences):\n","    # 順伝播\n","    H = rnn.forward(x[0,s], h)\n","    h = H\n","print(H)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZGkdN_4z7aXj","executionInfo":{"status":"ok","timestamp":1602038383245,"user_tz":-540,"elapsed":650,"user":{"displayName":"杉山明大","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLDWHHPNft0OzQcPMwj3-wE8ShJvR2UKW5D9pFfA=s64","userId":"08086586751154899568"}},"outputId":"6e93b736-9d93-466f-f158-4889f81ca816","colab":{"base_uri":"https://localhost:8080/"}},"source":["h_true = np.array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]]) # (batch_size, n_nodes)\n","H - h_true"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-9.57790736e-10,  3.93828459e-09, -1.37243750e-09,\n","        -1.88850646e-09]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"8Z69pjic7b_O"},"source":[""],"execution_count":null,"outputs":[]}]}